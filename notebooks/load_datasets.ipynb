{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb42237e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Dataset Download Notebook\n",
    "\n",
    "### Directory Breakdown\n",
    "This is the expected directory after running this notebook.\n",
    "\n",
    "```\n",
    "instanseg\n",
    "│   README.md\n",
    "│   setup.py\n",
    "└───notebooks\n",
    "        load_datasets.ipynb\n",
    "        ...\n",
    "│\n",
    "└───InstanSeg\n",
    "│   └───datasets\n",
    "│   │       segmentation_dataset.pth\n",
    "│   │\n",
    "│   └───models\n",
    "|   |   ...\n",
    "│   └───scripts\n",
    "│   |       train.py\n",
    "            test.py\n",
    "            inference.py\n",
    "|   \n",
    "│   \n",
    "└───Raw_Datasets\n",
    "    └─── Nucleus_Segmentation\n",
    "        └───CoNSeP\n",
    "            ...\n",
    "    └─── Cell_Segmentation\n",
    "```\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- **You must run the first cell**\n",
    "- **Run any of the dataset cells to download and process the dataset** (No specific order)\n",
    "- Run the **Save all the Datasets** cell\n",
    "\n",
    "### Custom Dataset\n",
    "\n",
    "- Follow instruction of the **Add your own dataset** cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8af1bc454e7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from instanseg.utils.utils import show_images\n",
    "import fastremap\n",
    "import os\n",
    "\n",
    "import os\n",
    "os.environ['INSTANSEG_RAW_DATASETS'] = os.path.abspath(\"../Raw_Datasets/\")\n",
    "\n",
    "if not os.path.exists(os.environ['INSTANSEG_RAW_DATASETS'] ):\n",
    "    os.mkdir(os.environ['INSTANSEG_RAW_DATASETS'])\n",
    "\n",
    "import os\n",
    "os.environ['INSTANSEG_DATASET_PATH'] = os.path.abspath(\"../instanseg/datasets/\")\n",
    "\n",
    "if not os.path.exists(os.environ['INSTANSEG_DATASET_PATH'] ):\n",
    "    os.mkdir(os.environ['INSTANSEG_DATASET_PATH'])\n",
    "\n",
    "Segmentation_Dataset = {}\n",
    "Segmentation_Dataset['Train']=[]\n",
    "Segmentation_Dataset['Test']=[]\n",
    "Segmentation_Dataset['Validation']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03120c",
   "metadata": {},
   "source": [
    "# TNBC_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed89dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_TNBC_2018\n",
    "Segmentation_Dataset = load_TNBC_2018(Segmentation_Dataset)\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-1]\n",
    "\n",
    "show_images(item['image'],item['nucleus_masks'],colorbar = False,labels = [1], axes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340b16c",
   "metadata": {},
   "source": [
    "# Cellpose\n",
    "\n",
    "The access to this dataset is restricted. Download the \"train.zip\" folder from https://www.cellpose.org/dataset. Place the file under \"../Raw_Datasets/Cell_Segmentation/Cellpose/\" and unzip it. Download test.zip and also place in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6510185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "abspath = os.path.abspath(\"../Raw_Datasets/Cell_Segmentation/Cellpose/\")\n",
    "if not os.path.exists(abspath):\n",
    "    print(\"The path {} does not exist. Did you download the dataset as described above?\".format(abspath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c80216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_Cellpose\n",
    "Segmentation_Dataset = load_Cellpose(Segmentation_Dataset)\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-2]\n",
    "\n",
    "show_images(item['image'],item['cell_masks'],colorbar = False,labels = [1], axes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee40e13",
   "metadata": {},
   "source": [
    "# Cell Image Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_CIL\n",
    "Segmentation_Dataset = load_CIL(Segmentation_Dataset)\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-2]\n",
    "\n",
    "show_images(item['image'],item['cell_masks'],colorbar = False,labels = [1], axes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff7165",
   "metadata": {},
   "source": [
    "# LyNSeC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9be5ca9026eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_LyNSeC\n",
    "Segmentation_Dataset = load_LyNSeC(Segmentation_Dataset)\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-1]\n",
    "\n",
    "show_images(item['image'],item['nucleus_masks'],colorbar = False,labels = [1], axes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda6517",
   "metadata": {},
   "source": [
    "# NuInsSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6901fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_NuInsSeg\n",
    "Segmentation_Dataset = load_NuInsSeg(Segmentation_Dataset)\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-1]\n",
    "\n",
    "show_images(item['image'],item['nucleus_masks'],colorbar = False,labels = [1], axes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cade833f",
   "metadata": {},
   "source": [
    "# IHC_TMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92916e1551fc9834",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_IHC_TMA\n",
    "Segmentation_Dataset = load_IHC_TMA(Segmentation_Dataset)\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-1]\n",
    "\n",
    "show_images(item['image'],item['nucleus_masks'],colorbar = False,labels = [1], axes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6403a6fe",
   "metadata": {},
   "source": [
    "# CoNSeP [Currently not available]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48530658650d2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from instanseg.utils.data_download import load_CoNSeP\n",
    "# Segmentation_Dataset = load_CoNSeP(Segmentation_Dataset)\n",
    "\n",
    "# item = Segmentation_Dataset['Train'][-1]\n",
    "\n",
    "# show_images(item['image'],item['nucleus_masks'],colorbar = False,labels = [1], axes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b83521",
   "metadata": {},
   "source": [
    "# MoNuSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f87fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_MoNuSeg\n",
    "Segmentation_Dataset = load_MoNuSeg(Segmentation_Dataset)\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-1]\n",
    "\n",
    "show_images(item['image'],item['nucleus_masks'],colorbar = False,labels = [1], axes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf253bf2",
   "metadata": {},
   "source": [
    "# PanNuke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f82e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_pannuke\n",
    "Segmentation_Dataset = load_pannuke(Segmentation_Dataset, no_zip=True)\n",
    "from instanseg.utils.data_loader import get_image\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-10]\n",
    "\n",
    "show_images(get_image(item['image']),get_image(item['nucleus_masks']),get_image(item['class_masks']),colorbar = False,labels = [1], axes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd798e5a88bf46a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Cross-platform dataset of multiplex fluorescent cellular object image annotations\n",
    "\n",
    "This is a dataset published in https://www.nature.com/articles/s41597-023-02108-z, available on [Synapse](https://www.synapse.org/#!Synapse:syn27624812/files/)\n",
    "\n",
    "\n",
    "### Instructions to download:\n",
    "\n",
    "1. Make an account at [Synapse](https://www.synapse.org/#)\n",
    "2. Download the Synapse [PyPI client](https://pypi.org/project/synapseclient/) (and openpyxl required for reading the Annotation Panel Table.xlsx) (```pip install synapseclient openpyxl```)\n",
    "3. Make empty directories by running the following cell\n",
    "4. Download \"Annotation Panel Table.xlsx\" and place it under the CPDMI_2023 folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import create_raw_datasets_dir\n",
    "create_raw_datasets_dir(\"Cell_Segmentation\", \"CPDMI_2023\",\"Vectra\")\n",
    "create_raw_datasets_dir(\"Cell_Segmentation\", \"CPDMI_2023\",\"Zeiss\")\n",
    "create_raw_datasets_dir(\"Cell_Segmentation\", \"CPDMI_2023\",\"CODEX\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ebbcc",
   "metadata": {},
   "source": [
    "5. In the command line, run the following commands, make sure to replace \"email\" and \"password\" with those created on step 1.\n",
    "\n",
    "### Annotation Panel Table (~36 kB)\n",
    "\n",
    "```\n",
    "cd ../Raw_Datasets/Cell_Segmentation/CPDMI_2023/\n",
    "synapse -u email -p password get -r syn52202417\n",
    "```\n",
    "\n",
    "\n",
    "### Vectra data (~19 GB)\n",
    "\n",
    "```\n",
    "cd ../Raw_Datasets/Cell_Segmentation/CPDMI_2023/Vectra\n",
    "synapse -u email -p password get -r syn50863072\n",
    "```\n",
    "\n",
    "### Zeiss data (~80 GB)\n",
    "\n",
    "```\n",
    "cd ../Raw_Datasets/Cell_Segmentation/CPDMI_2023/Zeiss\n",
    "synapse -u email -p password get -r syn51032932\n",
    "```\n",
    "\n",
    "### CODEX data (~33 GB)\n",
    "\n",
    "```\n",
    "cd ../Raw_Datasets/Cell_Segmentation/CPDMI_2023/CODEX\n",
    "synapse -u email -p password get -r syn50864867\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e67439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_CPDMI_Vectra\n",
    "Segmentation_Dataset = load_CPDMI_Vectra(Segmentation_Dataset)\n",
    "from instanseg.utils.data_loader import get_image\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-1]\n",
    "\n",
    "from instanseg.utils.utils import display_colourized\n",
    "\n",
    "show_images(display_colourized(get_image(item['image'])),get_image(item['cell_masks']),colorbar = False,labels = [1,2], axes = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(display_colourized(get_image(item['image'])),get_image(item['cell_masks']),colorbar = False,labels = [1,2], axes = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff37622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_CPDMI_Zeiss\n",
    "Segmentation_Dataset = load_CPDMI_Zeiss(Segmentation_Dataset)\n",
    "from instanseg.utils.data_loader import get_image\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-1]\n",
    "\n",
    "from instanseg.utils.utils import display_colourized\n",
    "\n",
    "show_images(display_colourized(get_image(item['image'])),get_image(item['cell_masks']),colorbar = False,labels = [1,2], axes = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8066fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_CPDMI_CODEX\n",
    "Segmentation_Dataset = load_CPDMI_CODEX(Segmentation_Dataset)\n",
    "from instanseg.utils.data_loader import get_image\n",
    "\n",
    "item = Segmentation_Dataset['Test'][-1]\n",
    "\n",
    "from instanseg.utils.utils import display_colourized\n",
    "\n",
    "show_images(display_colourized(get_image(item['image'])),get_image(item['cell_masks']),colorbar = False,labels = [1,2], axes = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8a9fdb",
   "metadata": {},
   "source": [
    "# Tissuenet\n",
    "\n",
    "The access to this dataset is restricted. Download the \"tissuenet_v1.1.zip\" folder from https://datasets.deepcell.org/. Place the file under \"../Raw_Datasets/Cell_Segmentation/TissueNet/\" and unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import load_tissuenet\n",
    "Segmentation_Dataset = load_tissuenet(Segmentation_Dataset, no_zip = True)\n",
    "from instanseg.utils.data_loader import get_image\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-10]\n",
    "\n",
    "from instanseg.utils.utils import display_colourized\n",
    "\n",
    "show_images(display_colourized(get_image(item['image'])),get_image(item['nucleus_masks']),get_image(item['cell_masks']),colorbar = False,labels = [1,2], axes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90377b4",
   "metadata": {},
   "source": [
    "# Save all the datasets !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED\n",
    "\n",
    "path = os.environ['INSTANSEG_DATASET_PATH'] \n",
    "\n",
    "import torch\n",
    "torch.save(Segmentation_Dataset,os.path.join(path,\"segmentation_dataset.pth\")) #This can ask for a lot of RAM (up to ~15 GB)\n",
    "\n",
    "# You can change the name to whatever you want, but make sure it ends with \"_dataset.pth\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab17996",
   "metadata": {},
   "source": [
    "## Download Example Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ccb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "examples_dir = \"../instanseg/examples/\"\n",
    "if not os.path.exists(examples_dir):\n",
    "    os.makedirs(examples_dir)\n",
    "\n",
    "#This is the LuCa-7color_[13860,52919]_1x1 from Perkin Elmer CC-BY 4.0\n",
    "download_url = \"https://downloads.openmicroscopy.org/images/Vectra-QPTIFF/perkinelmer/PKI_fields/LuCa-7color_%5b13860,52919%5d_1x1component_data.tif\"\n",
    "local_file_path = os.path.join(examples_dir, \"LuCa1.tif\")\n",
    "\n",
    "# Download the file using requests\n",
    "response = requests.get(download_url, stream=True)\n",
    "response.raise_for_status()\n",
    "with open(local_file_path, 'wb') as f:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        f.write(chunk)\n",
    "\n",
    "print(f\"File downloaded to {local_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34ed8d",
   "metadata": {},
   "source": [
    "## Add your own dataset [Optional]\n",
    "\n",
    "Assuming your dataset is in this format:\n",
    "```\n",
    "instanseg   \n",
    "└───Raw_Datasets\n",
    "    └─── Nucleus_Segmentation\n",
    "        └───My_Own_Dataset\n",
    "            └───img1.tiff\n",
    "                img1_masks.tiff\n",
    "                img2.tiff\n",
    "                img2_masks.tiff\n",
    "                ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4917da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL, add your own dataset.\n",
    "\n",
    "import numpy as np\n",
    "from instanseg.utils.utils import show_images\n",
    "import fastremap\n",
    "import os\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "\n",
    "def load_custom_dataset(Segmentation_Dataset):\n",
    "\n",
    "    data_path = os.path.abspath(\"../Raw_Datasets/Nucleus_Segmentation\") + \"/My_Own_Dataset/\"\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(data_path)\n",
    "    items = []\n",
    "\n",
    "    for file in sorted(os.listdir(data_path)):\n",
    "        file = os.path.join(data_path, file)\n",
    "        item = {}\n",
    "        if \"masks\" in file:\n",
    "            continue # Skip masks\n",
    "\n",
    "        mask_path = str(Path(file).parent / Path(file).stem) + \"_masks\" + Path(file).suffix\n",
    "        image = io.imread(str(file))\n",
    "        masks = io.imread(mask_path)\n",
    "        masks, _ = fastremap.renumber(masks, in_place=True)\n",
    "        masks = fastremap.refit(masks)\n",
    "        assert masks.squeeze().ndim == 2, r\"The mask should be a 2D array, found {}\".format(masks.shape)\n",
    "\n",
    "        item['nucleus_masks'] = masks # The masks should be a numpy array (or pytorch tensor) with shape (H, W). The values should be integers starting from 0. Each integer represents a different object.\n",
    "        # item[\"cell_masks\"] = cell_masks # Optional\n",
    "\n",
    "        item['image'] = image # The image should be a numpy array (or pytorch tensor) with shape (H, W, C) or shape (C, H, W). Where C is the number of channels. C must be smaller than H and W\n",
    "        \n",
    "        item[\"parent_dataset\"] = \"My_Own_Dataset\" #Important, this is the handle to call the dataset when training. \n",
    "        item['licence'] = \"TODO\" #optional but recommended for sharing.\n",
    "\n",
    "\n",
    "        # Pixel size should be in microns per pixel (usually it is in the range 0.2 to 1). \n",
    "        # If the segmentation task is not for cells, or the pixel size is not known, you can comment this line out. \n",
    "        # However, we strongly recommend you make sure the labels are of reasonable size, and fairly uniform across the dataset.\n",
    "        # A good label area is around 300 pixels. See load_Cellpose in data_download.py for an example of how to load a dataset without pixel size.\n",
    "        item['pixel_size'] = 0.25  \n",
    "        item['image_modality'] = \"Brightfield\" # Fluorescence or Brightfield, only used for padding.\n",
    "        item['file_name'] = file #optional\n",
    "        items.append(item)\n",
    "\n",
    "    assert len(items) > 0, \"No items found in the dataset folder.\"\n",
    "\n",
    "    np.random.seed(42) \n",
    "    np.random.shuffle(items)\n",
    "    Segmentation_Dataset['Train'] += items[:int(len(items) * 0.8)]\n",
    "    Segmentation_Dataset['Validation'] += items[int(len(items) * 0.8):int(len(items) * 0.9)]\n",
    "    Segmentation_Dataset['Test'] += items[int(len(items) * 0.9):]\n",
    "\n",
    "    return Segmentation_Dataset\n",
    "\n",
    "Segmentation_Dataset = {}\n",
    "Segmentation_Dataset['Train']=[]\n",
    "Segmentation_Dataset['Test']=[]\n",
    "Segmentation_Dataset['Validation']=[]\n",
    "\n",
    "\n",
    "Segmentation_Dataset = load_custom_dataset(Segmentation_Dataset)\n",
    "\n",
    "item = Segmentation_Dataset['Train'][-1]\n",
    "\n",
    "show_images(item['image'],item['nucleus_masks'],colorbar = False,labels = [1], axes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the custom dataset.\n",
    "path = os.environ['INSTANSEG_DATASET_PATH'] \n",
    "\n",
    "import torch\n",
    "torch.save(Segmentation_Dataset,os.path.join(path,\"custom_dataset.pth\")) # You can change the name to whatever you want, but make sure it ends with \"_dataset.pth\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330ade47",
   "metadata": {},
   "source": [
    "To train a model on your custom dataset, run the following command in your terminal:\n",
    "```\n",
    "cd instanseg/scripts\n",
    "python train.py -data custom_dataset.pth -source \"[My_Own_Dataset]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf23d8db",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_minimal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ae1f65caa71b38fc1ba7bd60417cf378993b2667a884a2b792dd708d4ac0a6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
